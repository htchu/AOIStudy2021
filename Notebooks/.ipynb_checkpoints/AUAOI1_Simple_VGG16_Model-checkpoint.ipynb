{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e5eQw8diP2t"
   },
   "source": [
    "<table width=\"100%\" border=\"3\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td ><img src=\"https://aidea-web.tw/images/web/logo_white.png\" alt=\"Aidea\" width=\"400\"/></td>\n",
    "      <td align='left'><h1>AUAI Exercise 1: Introduction to AIdea AOI </h1></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bM_8oFWlitDw"
   },
   "source": [
    "# (A) AIdea dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLJ474uIixh2"
   },
   "source": [
    "## Step 1: Load the AIdea AOI dataset from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "gq6SEJjKh57d"
   },
   "outputs": [],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader\n",
    "GoogleDriveDownloader.download_file_from_google_drive(file_id='1tovCO2gsjesjJ8OsfHgahyt-xxxxxxxxx',dest_path='./content', unzip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN8_whHgp-_m"
   },
   "source": [
    "## Step 2: check the train/test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ilq3w4KzqEv0"
   },
   "outputs": [],
   "source": [
    "#train dataset\n",
    "import pandas as pd\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O2Z_4htuqjXc"
   },
   "outputs": [],
   "source": [
    "type(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzg0nnWYqrPl"
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtC4JJitqE5D"
   },
   "outputs": [],
   "source": [
    "#test dataset\n",
    "df_test = pd.read_csv('test.csv')\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k9kidyW8q-h6"
   },
   "source": [
    "## Step 3: Build the lists of training images and labels from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KcBrQpTlqFIA"
   },
   "outputs": [],
   "source": [
    "#limit the amount of training images for the class process\n",
    "#train_num = 480\n",
    "train_num = df_train.shape[0]\n",
    "if train_num >= df_train.shape[0]:\n",
    "  train_num = df_train.shape[0]\n",
    "train_files = df_train.iloc[:train_num,0].values\n",
    "train_labels = df_train.iloc[:train_num,1].values\n",
    "print(train_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqIlE6rZrFMR"
   },
   "source": [
    "## Step 4: read images of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uEOASVlOrETO"
   },
   "outputs": [],
   "source": [
    "train_path =\"train_images/\"\n",
    "train_images = []\n",
    "from tensorflow.keras.preprocessing import image\n",
    "for file in train_files:\n",
    "    img = image.load_img(train_path+file, color_mode=\"rgb\", target_size = (224, 224))\n",
    "    train_images.append(img)\n",
    "    if len(train_images)%100 == 0:\n",
    "      print('.', end='')\n",
    "print(len(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fQnDDEtqrLhJ"
   },
   "source": [
    "## Step 5: show AOI images of the classes: \n",
    "0 (normal), 1 (void), 2 (horizontal  defect) 3 (vertical defect), 4 (edge defect), 5 (particle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nCQCf5CLrMV2"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7ednVO9rO0e"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "curclass = 0\n",
    "fig,ax=plt.subplots(2, 3)\n",
    "fig.set_size_inches(10,10)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        sel=random.randint(0,train_num)\n",
    "        while train_labels[sel]!=curclass:\n",
    "          sel +=1\n",
    "          if sel == train_num -1:\n",
    "            sel = 0\n",
    "        curclass += 1\n",
    "        curclass %= 6\n",
    "        #sel=random.randint(0,train_num)\n",
    "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
    "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GESfA-iArSR5"
   },
   "outputs": [],
   "source": [
    "# Class 0-normal\n",
    "import random\n",
    "curclass = 0\n",
    "fig,ax=plt.subplots(2, 3)\n",
    "fig.set_size_inches(10,10)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        sel=random.randint(0,train_num)\n",
    "        while train_labels[sel]!=curclass:\n",
    "          sel +=1\n",
    "          if sel == train_num -1:\n",
    "            sel = 0\n",
    "        #sel=random.randint(0,train_num)\n",
    "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
    "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErzrBxYKrTDQ"
   },
   "outputs": [],
   "source": [
    "# Class 1-void\n",
    "import random\n",
    "curclass = 1\n",
    "fig,ax=plt.subplots(2, 3)\n",
    "fig.set_size_inches(10,10)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        sel=random.randint(0,train_num)\n",
    "        while train_labels[sel]!=curclass:\n",
    "          sel +=1\n",
    "          if sel == train_num -1:\n",
    "            sel = 0\n",
    "        #sel=random.randint(0,train_num)\n",
    "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
    "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppkl7wT0rUmM"
   },
   "outputs": [],
   "source": [
    "# Class 2-horizontal defect\n",
    "import random\n",
    "curclass = 2\n",
    "fig,ax=plt.subplots(2, 3)\n",
    "fig.set_size_inches(10,10)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        sel=random.randint(0,train_num)\n",
    "        while train_labels[sel]!=curclass:\n",
    "          sel +=1\n",
    "          if sel == train_num -1:\n",
    "            sel = 0\n",
    "        #sel=random.randint(0,train_num)\n",
    "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
    "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "olT1R8x4rW5S"
   },
   "outputs": [],
   "source": [
    "# Class 3-vertical defect\n",
    "import random\n",
    "curclass = 3\n",
    "fig,ax=plt.subplots(2, 3)\n",
    "fig.set_size_inches(10,10)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        sel=random.randint(0,train_num)\n",
    "        while train_labels[sel]!=curclass:\n",
    "          sel +=1\n",
    "          if sel == train_num -1:\n",
    "            sel = 0\n",
    "        #sel=random.randint(0,train_num)\n",
    "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
    "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9uSRH1OprYea"
   },
   "outputs": [],
   "source": [
    "# Class 4-edge defect\n",
    "import random\n",
    "curclass = 4\n",
    "fig,ax=plt.subplots(2, 3)\n",
    "fig.set_size_inches(10,10)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        sel=random.randint(0,train_num)\n",
    "        while train_labels[sel]!=curclass:\n",
    "          sel +=1\n",
    "          if sel == train_num -1:\n",
    "            sel = 0\n",
    "        #sel=random.randint(0,train_num)\n",
    "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
    "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-28YsO7raHn"
   },
   "outputs": [],
   "source": [
    "# Class 5-particle\n",
    "import random\n",
    "curclass = 5\n",
    "fig,ax=plt.subplots(2, 3)\n",
    "fig.set_size_inches(10,10)\n",
    "for i in range(2):\n",
    "    for j in range (3):\n",
    "        sel=random.randint(0,train_num)\n",
    "        while train_labels[sel]!=curclass:\n",
    "          sel +=1\n",
    "          if sel == train_num -1:\n",
    "            sel = 0\n",
    "        #sel=random.randint(0,train_num)\n",
    "        ax[i,j].imshow(train_images[sel], cmap='gray')\n",
    "        ax[i,j].set_title('No. {} Label:{} '.format(sel, train_labels[sel]))       \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owIZdbTrrbJx"
   },
   "source": [
    "## Step 6: Show statistics of training images in the 6 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gniw-TGTrdT_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "labels, counts = np.unique(train_labels, return_counts=True)\n",
    "print(labels, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgrKX1ZPrfyB"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "plt.bar(labels, counts, width=0.7, align='center')\n",
    "plt.title(\"Label Distribution\")\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(labels)\n",
    "plt.ylim(0, 680)\n",
    "\n",
    "for a, b in zip(labels, counts):\n",
    "    plt.text(a, b, '%d' % b, ha='center', va='bottom', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Ul3nBZKrhPS"
   },
   "source": [
    "# AOI02-Training a Deep Learning Model by Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk8NeqhvsxyQ"
   },
   "source": [
    "## Step 7: convert images into input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BndyzEzetjsQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Assign a list for storing image data\n",
    "img_list=[]\n",
    "for i in range(train_num):\n",
    "    x=image.img_to_array(train_images[i])\n",
    "    x = preprocess_input(x)\n",
    "    img_list.append(x)\n",
    "X_train = np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CortBPnfu14N"
   },
   "outputs": [],
   "source": [
    "print (X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZKbEpbOvCaY"
   },
   "source": [
    "## Step 8: Configure a customized VGG-16 Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iGw3UmLMvD88"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jWRMhRHqvKUd"
   },
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "#input shape\n",
    "input_layer = Input(shape=(224, 224, 3))\n",
    "\n",
    "#Use the VGG16 model \n",
    "model = VGG16(input_tensor=input_layer, include_top=True,weights='imagenet')\n",
    "\n",
    "#Summary of the customize VGG16 model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X8LwxSqxvZFa"
   },
   "outputs": [],
   "source": [
    "last_layer = model.get_layer('fc2').output\n",
    "out = Dense(num_classes, activation='softmax', name='output')(last_layer)\n",
    "custom_vgg_model = Model(input_layer, out)\n",
    "custom_vgg_model.summary()\n",
    "\n",
    "for layer in custom_vgg_model.layers[:-1]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXfSulNmDXvs"
   },
   "source": [
    "## Step 9: Compile and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WNYygrmjwvV1"
   },
   "outputs": [],
   "source": [
    "custom_vgg_model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnJXlluSwekI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.keras import utils\n",
    "# one-hot encoding\n",
    "y_train = utils.np_utils.to_categorical(train_labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxwaWYTVwpMb"
   },
   "outputs": [],
   "source": [
    "hist = custom_vgg_model.fit(X_train, y_train, batch_size=32, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AhxdnY5j0NLn"
   },
   "source": [
    "## Step 10: Analyze training results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvVaagtPx1Qp"
   },
   "outputs": [],
   "source": [
    "y_predicts = custom_vgg_model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pP7IPh0ryGV4"
   },
   "outputs": [],
   "source": [
    "print(y_predicts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fV5RxaIHyOl6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicts = np.argmax(y_predicts,axis=1)\n",
    "print(predicts[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nXbiHf1vzDbg"
   },
   "outputs": [],
   "source": [
    "print(train_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "brhpouMc0N_V"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion=confusion_matrix(train_labels, predicts)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1gvQhUN0WhS"
   },
   "outputs": [],
   "source": [
    "overkill= []\n",
    "underkill = []\n",
    "for i in range(train_num):\n",
    "  if train_labels[i] == 0 and predicts[i] !=0:\n",
    "    overkill.append(i)\n",
    "  if train_labels[i] != 0 and predicts[i] ==0:\n",
    "    underkill.append(i)\n",
    "print('# of overkill= {}; # of underkill= {} '.format(len(overkill), len(underkill)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vH_ab3UQDimc"
   },
   "source": [
    "## Step 11: clean memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQpPoe_52ikr"
   },
   "outputs": [],
   "source": [
    "del X_train\n",
    "del img_list\n",
    "del train_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m96WeuVj2TUo"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vv54V0lKDtCc"
   },
   "source": [
    "# AOI03-Inference by our Deep Learning Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVdlGzvK0tmg"
   },
   "source": [
    "## Step 12: Build the lists of test images and labels from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "936K2zHy01p-"
   },
   "outputs": [],
   "source": [
    "test_files  = df_test.iloc[:,0].values\n",
    "test_labels = df_test.iloc[:,1].values\n",
    "print(test_labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o1ASFev20fQt"
   },
   "source": [
    "## Step 13: Read test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuiIHs6M9m4N"
   },
   "outputs": [],
   "source": [
    "#limit the amount of test images for the class process\n",
    "#test_num = len(test_files)\n",
    "test_num = 1024\n",
    "print(test_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "derLidJ70eOS"
   },
   "outputs": [],
   "source": [
    "test_path =\"test_images/\"\n",
    "test_images = []\n",
    "from tensorflow.keras.preprocessing import image\n",
    "for file in test_files[0:test_num]:\n",
    "    img = image.load_img(test_path+file, color_mode=\"rgb\", target_size = (224, 224))\n",
    "    test_images.append(img)\n",
    "    if len(test_images)%100 == 0:\n",
    "      print('.', end='')\n",
    "print('Finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIp8_kI0EF6f"
   },
   "source": [
    "## Step 14: convert images into input vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WsWYlUiv1jIU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#Assign a list for storing image data\n",
    "img_list=[]\n",
    "for i in range(test_num):\n",
    "    x=image.img_to_array(test_images[i])\n",
    "    x = preprocess_input(x)\n",
    "    img_list.append(x)\n",
    "X_test = np.array(img_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4mhFmtlFD7tO"
   },
   "source": [
    "## Step 15: Predict the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lRlanRxv1d5h"
   },
   "outputs": [],
   "source": [
    "y_predicts = custom_vgg_model.predict(X_test, batch_size=10)\n",
    "predict = np.argmax(y_predicts,axis=1)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zOTt-Vl_mor"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_out = pd.DataFrame(predict) \n",
    "df_out.to_csv(\"ans.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AUAOI1_Simple_VGG16_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
