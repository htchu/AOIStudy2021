{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0KvrRl029pPB"
   },
   "source": [
    "<table width=\"100%\" border=\"3\">\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td ><img src=\"https://aidea-web.tw/images/web/logo_white.png\" alt=\"Aidea\" width=\"400\"/></td>\n",
    "      <td align='left'><h1>Exercise 1: Review Transfer Learning TF2.0</h1></td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZD4ZBffHX71W"
   },
   "source": [
    "# (2) TensorFlow 2.0 Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nwc-pIjUFNmb"
   },
   "source": [
    "## Step 1: Tensorflow basic model training\n",
    "(define), (compile), (fit), (evaluate), (prediction）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iqQjygi1m_qS"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c20jGAYlcW5j"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZxYH9F7wAGra"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V0-9g1yIALYt"
   },
   "outputs": [],
   "source": [
    "x_train = x_train[..., tf.newaxis]\n",
    "x_test  = x_test[..., tf.newaxis]\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R8ZbsvLsAhra"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters = 32, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu', input_shape = (28,28,1)),\n",
    "    tf.keras.layers.Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same', \n",
    "                 activation ='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GzifkxmEAnxc"
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.SGD(learning_rate=0.01) #lr =0.01\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mx1qPZhMC2h8"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-JAMGEz0CyQQ"
   },
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUSlrsB5C7-K"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQBQqZKmDFui"
   },
   "outputs": [],
   "source": [
    "y_predicts = model.predict(x_test)\n",
    "y_predicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uT1s_j1k00LM"
   },
   "outputs": [],
   "source": [
    "y_predicts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1KhPEN-vDTBk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "predicts = np.argmax(y_predicts,axis=1)\n",
    "print(predicts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7L40BlU6DrHH"
   },
   "outputs": [],
   "source": [
    "print(y_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OQtcWITNcMHK"
   },
   "source": [
    "## Step 2: Keras Applications Models\n",
    "<img src=\"https://miro.medium.com/max/1571/1*XB4SlSGxGKFQbIBoil0aDg.png\" alt=\"Pre-train models\" width=\"500\">\n",
    "\n",
    "Pre-train models of tf.Keras includes Xception、VGG16、VGG19、ResNet50、InceptionV3、InceptionResNetV2、MobileNet、DenseNet、NASNet、MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpNJ4wqdFOk7"
   },
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YxLyEiuFEIgI"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "model = InceptionV3(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpyO_On4Egdx"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "model = Xception(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "su_yDmG6EkkX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import NASNetLarge\n",
    "from tensorflow.keras.applications.nasnet import preprocess_input\n",
    "model = NASNetLarge(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yh36dHu0EtH_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "model = InceptionResNetV2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jZ8_jQYQExo3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "model = MobileNetV2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_WZxmhSPE4D8"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "model = ResNet50V2(include_top = True, input_shape=(299,299,3), weights=None, classes=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCVO6g04GFMi"
   },
   "source": [
    "## Step 3: Keras Applications preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PZzsTx4cHrze"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "x = image.img_to_array(train_images[0])\n",
    "img_array = preprocess_input(x, mode = 'tf' )\n",
    "print(img_array[0 , 0 , 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JaW40jTcIh0g"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "x = image.img_to_array(train_images[0])\n",
    "img_array = preprocess_input(x, mode = 'torch' )\n",
    "print(img_array[0 , 0 , 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BkwlHXQunZ02"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.python.keras.applications.imagenet_utils import preprocess_input\n",
    "x = image.img_to_array(train_images[0])\n",
    "img_array = preprocess_input(x, mode = 'caffe' )\n",
    "print(img_array[0 , 0 , 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VDkl3H-woXKA"
   },
   "source": [
    "## Step 4: Tranfer learning\n",
    "<img src=\"https://miro.medium.com/max/1280/0*L8egayRvFZOAmvqc.png\" alt=\"Pre-train models\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Y-15yJXn_LM"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Activation\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSObvzWmofw_"
   },
   "outputs": [],
   "source": [
    "#the InceptionV3 model \n",
    "num_classes = 6\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "base_model = InceptionV3(include_top = False, input_shape=(299,299,3), weights='imagenet', classes=num_classes)\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yv9FohfRfmRs"
   },
   "outputs": [],
   "source": [
    "base_model.trainable = False\n",
    "last_layer = base_model.output\n",
    "last_layer=Flatten()(last_layer)\n",
    "last_layer=Dropout(0.3)(last_layer)\n",
    "out = Dense(num_classes, activation='softmax', name='softmax')(last_layer)\n",
    "custom_model = Model(base_model.input, out)\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AUAOI2_TransferLearning.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
